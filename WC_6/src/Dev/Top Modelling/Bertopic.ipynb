{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "P2GPZcnq6IXQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches:   1%|          | 1/157 [14:27<37:35:35, 867.53s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 38\u001b[0m\n\u001b[0;32m     23\u001b[0m hdbscan_model \u001b[39m=\u001b[39m HDBSCAN(min_cluster_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[0;32m     24\u001b[0m                         metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     25\u001b[0m                         prediction_data\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m topic_model \u001b[39m=\u001b[39m BERTopic(embedding_model\u001b[39m=\u001b[39membedding_model,\n\u001b[0;32m     28\u001b[0m                        vectorizer_model\u001b[39m=\u001b[39mvectorizer_model,\n\u001b[0;32m     29\u001b[0m                        umap_model\u001b[39m=\u001b[39mumap_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m                        nr_topics\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     36\u001b[0m                        verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 38\u001b[0m topics, probs \u001b[39m=\u001b[39m topic_model\u001b[39m.\u001b[39mfit_transform(slice_docs)\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\bertopic\\_bertopic.py:373\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[1;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[39mif\u001b[39;00m embeddings \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    371\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model \u001b[39m=\u001b[39m select_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model,\n\u001b[0;32m    372\u001b[0m                                           language\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlanguage)\n\u001b[1;32m--> 373\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extract_embeddings(documents\u001b[39m.\u001b[39mDocument\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist(),\n\u001b[0;32m    374\u001b[0m                                           images\u001b[39m=\u001b[39mimages,\n\u001b[0;32m    375\u001b[0m                                           method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdocument\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    376\u001b[0m                                           verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    377\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mTransformed documents to Embeddings\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    378\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\bertopic\\_bertopic.py:3126\u001b[0m, in \u001b[0;36mBERTopic._extract_embeddings\u001b[1;34m(self, documents, images, method, verbose)\u001b[0m\n\u001b[0;32m   3124\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model\u001b[39m.\u001b[39membed_words(words\u001b[39m=\u001b[39mdocuments, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[0;32m   3125\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdocument\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 3126\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model\u001b[39m.\u001b[39membed_documents(documents, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[0;32m   3127\u001b[0m \u001b[39melif\u001b[39;00m documents[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m images \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMake sure to use an embedding model that can either embed documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3129\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mor images depending on which you want to embed.\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\bertopic\\backend\\_base.py:69\u001b[0m, in \u001b[0;36mBaseEmbedder.embed_documents\u001b[1;34m(self, document, verbose)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_documents\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m     56\u001b[0m                     document: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m     57\u001b[0m                     verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Embed a list of n words into an n-dimensional\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m    matrix of embeddings\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39m        that each have an embeddings size of `m`\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed(document, verbose)\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\bertopic\\backend\\_sentencetransformers.py:65\u001b[0m, in \u001b[0;36mSentenceTransformerBackend.embed\u001b[1;34m(self, documents, verbose)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m     52\u001b[0m           documents: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m     53\u001b[0m           verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m     54\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Embed a list of n documents/words into an n-dimensional\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39m    matrix of embeddings\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39m        that each have an embeddings size of `m`\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model\u001b[39m.\u001b[39mencode(documents, show_progress_bar\u001b[39m=\u001b[39mverbose)\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[0;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(features)\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[0;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrans_features, return_dict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[0;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:551\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    550\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids\u001b[39m=\u001b[39minput_ids, position_ids\u001b[39m=\u001b[39mposition_ids, inputs_embeds\u001b[39m=\u001b[39minputs_embeds)\n\u001b[1;32m--> 551\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[0;32m    552\u001b[0m     embedding_output,\n\u001b[0;32m    553\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[0;32m    554\u001b[0m     head_mask\u001b[39m=\u001b[39mhead_mask,\n\u001b[0;32m    555\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[0;32m    556\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    557\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m    558\u001b[0m )\n\u001b[0;32m    559\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    560\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:341\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    339\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[1;32m--> 341\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    342\u001b[0m     hidden_states,\n\u001b[0;32m    343\u001b[0m     attention_mask,\n\u001b[0;32m    344\u001b[0m     head_mask[i],\n\u001b[0;32m    345\u001b[0m     position_bias,\n\u001b[0;32m    346\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[0;32m    347\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    348\u001b[0m )\n\u001b[0;32m    349\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:311\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add self attentions if we output attention weights\u001b[39;00m\n\u001b[0;32m    310\u001b[0m intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 311\u001b[0m layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    312\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[0;32m    313\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:278\u001b[0m, in \u001b[0;36mMPNetOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 278\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    279\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    280\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\alimes001\\AppData\\Local\\anaconda3\\envs\\PY311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mlinear(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from bertopic import BERTopic\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from bertopic.representation import KeyBERTInspired\n",
        "\n",
        "docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']\n",
        "\n",
        "slice_docs=docs[:5000]\n",
        "\n",
        "# setting Models\n",
        "embedding_model= SentenceTransformer('all-mpnet-base-v2')\n",
        "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
        "representation_model = KeyBERTInspired()\n",
        "\n",
        "umap_model = UMAP(  n_neighbors=10,\n",
        "                    n_components=5,\n",
        "                    metric='cosine')\n",
        "\n",
        "\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=10,\n",
        "                        metric='euclidean',\n",
        "                        prediction_data=True)\n",
        "\n",
        "topic_model = BERTopic(embedding_model=embedding_model,\n",
        "                       vectorizer_model=vectorizer_model,\n",
        "                       umap_model=umap_model,\n",
        "                       hdbscan_model=hdbscan_model,\n",
        "                       representation_model=representation_model,\n",
        "                       language=\"english\",\n",
        "                       top_n_words=10,\n",
        "                       n_gram_range=(1, 2),\n",
        "                       nr_topics=\"auto\",\n",
        "                       verbose=True)\n",
        "\n",
        "topics, probs = topic_model.fit_transform(slice_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fnhc5aZT6c9e",
        "outputId": "29164531-880e-4fd8-ac3b-f36ea7ddb252"
      },
      "outputs": [],
      "source": [
        "topic_model.get_topic_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "gUuyGYUg7p57",
        "outputId": "da09d53c-af0b-4418-ee3c-598c744b7fc3"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_heatmap()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "pElRuXMb77Ox",
        "outputId": "cb422a2a-ddd1-451e-88dd-1b11eda8d40c"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_barchart()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km5WtYqgC__H"
      },
      "outputs": [],
      "source": [
        "similar_topics, similarity = topic_model.find_topics(\"Leader\", top_n = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9aAmiSoDTiT",
        "outputId": "44f08b5a-0bd5-4229-81ed-9b6efbadd50b"
      },
      "outputs": [],
      "source": [
        "print(\"Most Similar Topic Info: \\n{}\".format(topic_model.get_topic(similar_topics[0])))\n",
        "print(\"Similarity Score: {}\".format(similarity[0]))\n",
        "\n",
        "print(\"\\n Most Similar Topic Info: \\n{}\".format(topic_model.get_topic(similar_topics[1])))\n",
        "print(\"Similarity Score: {}\".format(similarity[1]))\n",
        "\n",
        "print(\"\\n Most Similar Topic Info: \\n{}\".format(topic_model.get_topic(similar_topics[2])))\n",
        "print(\"Similarity Score: {}\".format(similarity[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03c96895d9084d938a459752da0fc43d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ebc4bddf9aa4655a98a3732284b702f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24bb6f3d220847e898da255ceac32ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ebc4bddf9aa4655a98a3732284b702f",
            "max": 589,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae56478d71a74f39947cf33fd14f2802",
            "value": 589
          }
        },
        "5fb97512a4ba477d8553305c570d7b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c49dee5c757e4d989b5becbc5e749436",
            "placeholder": "​",
            "style": "IPY_MODEL_aef7bac7f9664655961eb078faee0f8b",
            "value": "Batches: 100%"
          }
        },
        "665c9af163d44b7d9c1fa71e2917de09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fb97512a4ba477d8553305c570d7b21",
              "IPY_MODEL_24bb6f3d220847e898da255ceac32ebc",
              "IPY_MODEL_fb500336b0c940949ce3e70622b2ac6c"
            ],
            "layout": "IPY_MODEL_a39e4e908bc8426385b43be95788e22d"
          }
        },
        "6eb8239b39dc43c28a7fc2d0ef6457a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a39e4e908bc8426385b43be95788e22d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae56478d71a74f39947cf33fd14f2802": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aef7bac7f9664655961eb078faee0f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c49dee5c757e4d989b5becbc5e749436": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb500336b0c940949ce3e70622b2ac6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c96895d9084d938a459752da0fc43d",
            "placeholder": "​",
            "style": "IPY_MODEL_6eb8239b39dc43c28a7fc2d0ef6457a3",
            "value": " 589/589 [04:41&lt;00:00, 43.55it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
